---
title: "DOHMH Dashboard Data"
author: "Alexander M Vogel"
date: "May 27, 2021"
output:
  html_document: 
    toc: yes
    keep_md: yes
---

```{r load packages, include=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE)
library(readxl)
library(tidyverse)
library(survey)
library(srvyr)
library(fastDummies)
library(writexl)
library(glue)
library(naniar)
```

# Data Sources

### Zip Code Crosswalk (ZIP to ZCTA to Borough) compiled by [Baruch College CUNY](https://www.baruch.cuny.edu/confluence/display/geoportal/NYC+Geographies)
```{r zip to zcta to county}
url = "http://faculty.baruch.cuny.edu/geoportal/resources/nyc_geog/zip_to_zcta10_nyc_revised.xls"
destfile = "zip_to_zcta10_nyc_revised.xls"
curl::curl_download(url, destfile)
zip_to_zcta = read_excel(destfile, sheet = "zip_to_zcta")
```

### ZCTA Crosswalk (ZCTA to Neighborhood to Borough) compiled by [Baruch College CUNY](https://www.baruch.cuny.edu/confluence/display/geoportal/NYC+Geographies)
```{r zcta to borough}
url = "http://faculty.baruch.cuny.edu/geoportal/resources/nyc_geog/nyc_zcta10_to_puma10.xls"
destfile = "nyc_zcta10_to_puma10.xls"
curl::curl_download(url, destfile)
zcta_to_borough = read_excel(destfile, sheet = "zctas_assigned")
```

### Census Tract, NTA, PUMA Crosswalk from [NYC Planning](https://www1.nyc.gov/site/planning/data-maps/nyc-population/geographic-reference.page)
```{r tract nta puma borough}
url = "https://www1.nyc.gov/assets/planning/download/office/data-maps/nyc-population/census2010/nyc2010census_tabulation_equiv.xlsx"
destfile = "nyc2010census_tabulation_equiv.xlsx"
curl::curl_download(url, destfile)
tract_nta_puma = read_excel(destfile, sheet = 1, skip = 5, col_names = c("borough_name", "fips", "borough_code", "tract", "puma", "nta_code", "nta_name"))
```

### Zip Code UHF Neighborhood Crosswalk from [nyc.gov](https://www1.nyc.gov/assets/doh/downloads/pdf/data/appb.pdf)
```{r uhf zip}
#Download table, convert pdf to excel table, separate zip code columns by comma delimiter, move columns beyond after the first zip code column below the data in the first zip code column alongside their respective names from the neighborhood column to create a table where each line has a zip code
uhf <- read_csv("C:/Users/Alex/Downloads/uhf.csv", col_names=TRUE, col_types = "cc") #"cc"=character type, character type
```

### School Distrist Crosswalk from [Github](https://github.com/vr00n/NYC-LocalGeo-CrossWalk)
```{r school districts}
url = "https://github.com/vr00n/NYC-LocalGeo-CrossWalk/raw/master/MASTER-CROSSWALK-NAD83.csv"
destfile = "MASTER-CROSSWALK-NAD83.csv"
curl::curl_download(url, destfile)
districts = read_csv(destfile)
```

### Census Demographics by Zip Code (US Census data combined with NYC GIS data) from R package [nycgeo](https://github.com/mfherman/nycgeo)
```{r demographics}
#skips the steps of analysing data that is tied to GIS data (coordinates, etc.)
remotes::install_github("mfherman/nycgeo")
demo = nycgeo::nta_acs_data
```

### Select NYC Indicators from the Environment and Health Portal by [nyc.gov](http://a816-dohbesp.nyc.gov/IndicatorPublic/BuildATable.aspx)
```{r nyc indicators}
#Select the indicators needed and export dataset, unzip file and import
nycdata <- read_csv("C:/Users/Alex/Downloads/DataPackage/Data.csv", n_max = 1787) %>% select(-c(15,16))
```

### Mental Health Facilities Database from [nyc.gov](https://www1.nyc.gov/site/planning/data-maps/open-data/dwn-selfac.page)
```{r mh facilities}
#Download here https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/facilities_20210315csv.zip
#Filtered in Excel by Mental Health facility subgroup
facdbmh <- read_csv("C:/Users/Alex/Downloads/facdbmh.csv")
```

### Parks in NYC from [Dept of Parks and Rec](https://data.cityofnewyork.us/api/views/ghu2-eden/rows.csv?accessType%3DDOWNLOAD&sa=D&source=editors&ust=1617036530589000&usg=AFQjCNG2TyjP1v9A3pIBAUxrqOzjghVJAg)
```{r parks}
url = "https://data.cityofnewyork.us/api/views/ghu2-eden/rows.csv?accessType%3DDOWNLOAD&sa=D&source=editors&ust=1617036530589000&usg=AFQjCNG2TyjP1v9A3pIBAUxrqOzjghVJAg"
destfile = "OpenData_ParksProperties.csv"
curl::curl_download(url, destfile)
parks = read_csv(destfile)
```

### Youth Risk Behavior Survey (YRBS) from the [CDC](https://www.cdc.gov/HEALTHYYOUTH/DATA/YRBS/DATA.HTM)
```{r yrbs}
#Download SAS format program, SAS input program, and ASCII data file for the combined dataset(2019, Districts)
#Open the format program THEN the input program using SAS, following the instructions
#Export the .sas7bdat as .csv
#Open .csv in Excel, filter by 5 boroughs and NYC; filter by survey year 2019, save
yrbs = read_csv("C:/Users/Alex/Downloads/yrbsnyc19.csv", na = "Missing")
```

# Data Transformation

```{r start with geo ids}
dat = zip_to_zcta %>% 
          filter(ziptype == "ZIP Code area") %>% #only zip codes
          select(c("zipcode", borough_code = "bcode", zcta = "zcta5")) %>% #only the columns we want, rename two
          mutate(borough_name = factor(borough_code, #convert from numeric to character
                                  levels = c("36005", "36047", "36061", "36081", "36085"), 
                                  labels = c("bronx", "brooklyn", "manhattan", "queens", "staten_island"))) %>%
     left_join(zcta_to_borough[,c(1,4)], by = c("zcta" = "zcta10")) %>% #add borough, join by zcta
          rename(puma = puma10) %>% #ensure that there will be no name conflicts
          mutate(puma = str_remove(puma, "^0+")) %>% #remove leading zero
     left_join(
          summarise(
               group_by_all(tract_nta_puma[,c(5,6,7)])), #collapse rows
                  by = "puma") %>% #add nta, join by puma
     left_join(uhf, by = c("zipcode"="Zip Code.1")) %>% #add uhf, join by zipcode
     left_join(summarise(group_by_all(select(districts, c(8,18)))), by=c("nta_code"="NTACode"), .after = "uhf") #add school districts, join by nta
```

```{r add demographics}
dat = left_join(dat, 
                rename(
                     select(demo, c(1, contains("pct_est"))), #only the columns with %
                nta_code = nta_id))#join by nta
```

```{r add nycdata}
nycdata$geo_entity_name = recode(nycdata$geo_entity_name, 
                                 "Hudson Yards-Chelsea-Flatiron-Union Square"=
                                      "Hudson Yards-Chelsea-Flat Iron-Union Square") #fixing spelling differences
dat = left_join(dat, 
                filter(nycdata, geo_type_name == "NTA") %>% #remove borough level indicators
                     select(c(7,12,14)) %>% #remove redudant variables
                     pivot_wider(names_from = name,values_from = data_value), #pivot wider
                by = c("nta_name" = "geo_entity_name")) #join by nta name
```

```{r add facdbmh}
facdbmh = facdbmh %>% 
   group_by(postcode) %>% 
   add_count(postcode, name = "num_mh_fac") %>%  #count unique facilities by zip code
                     select(9,37) %>% #keep only zip code and facility count 
                     distinct() #remove duplicates
facdbmh$postcode=as.character(facdbmh$postcode) #both join columns need to be of the same type
dat = left_join(dat, facdbmh, by = c("zipcode" = "postcode")) #join by zip code
```

```{r add parks}
parks = separate_rows(parks,ZIPCODE,sep=", ") %>% 
   filter(ZIPCODE!="1") %>%
   group_by(ZIPCODE) %>%
   add_count(ZIPCODE, name = "num_parks") %>%
   select(13,37) %>%
   distinct()
dat = left_join(dat, parks, by = c("zipcode" = "ZIPCODE"))
```

```{r add yrbs, message=FALSE}
yrbs = yrbs %>% 
   select(1,7,8,9,10,20,21,22,96,106,115,117,123,176,186,214,215,258,259,260,261,302,310) %>%
   filter(`Site code`!="New York City, NY") %>%
   dummy_cols(c("Sexual identity", "Transgender"), ignore_na = TRUE) #create dummy variables for character/factor responses
yrbs$`Site code` = recode(yrbs$`Site code`, #simplify borough names
                                     "Borough of Bronx, NY" = "bronx", 
                           "Borough of Brooklyn, NY" = "brooklyn", 
                           "Borough of Manhattan, NY" = "manhattan", 
                           "Borough of Queens, NY" = "queens", 
                           "Borough of Staten Island, NY" = "staten_island")
yrbs = svydesign(id = ~`Analysis primary sampling unit`, #PSU
                  strata = ~`Analysis stratum`, #strata
                  weights = ~`Analysis weight`, #weights
                  data = yrbs, nest = TRUE) #yrbs can now be analyzed with weights
yrbs$variables = yrbs$variables %>%
     mutate_at(c(6,7,11:16), ~ recode(., `2`=0, `1`=1)) %>% #binary variables from 1/2 to 1/0
     mutate_at(c(8,9,10,21), ~ factor(.)) %>% #factor the character variables
     select(-c(16:20,22,23)) #100% NA columns need removal
yrbs = as_survey_design(yrbs) %>%
   group_by(`Site code`) %>% #group by borough and collapse rows by mean of 0s and 1s to get proportion
   summarise(obesity_pct = survey_mean(`Had obesity`, na.rm = TRUE), #binary variables
             overweight_pct = survey_mean(`Were Overweight`, na.rm = TRUE),
             unsafe_pct = survey_mean(`Did not go to school because they felt unsafe at school or on their way to or from school`, na.rm = TRUE),
             fight_pct = survey_mean(`Were in a physical fight`, na.rm = TRUE),
             bullied_pct = survey_mean(`Were bullied on school property`, na.rm = TRUE),
             phys_active_5_days_pct = survey_mean(`Were physically active at least 60 minutes per day on 5 or more days`, na.rm = TRUE),
             eight_plus_hrs_sleep_pct = survey_mean(`Got 8 or more hours of sleep`, na.rm = TRUE),
             
             bisexual_pct = survey_mean(`Sexual identity_Bisexual`, na.rm = TRUE), #dummy coded multicategory response variables
             gay_or_lesbian_pct = survey_mean(`Sexual identity_Gay or lesbian`, na.rm = TRUE),
             heterosexual_pct = survey_mean(`Sexual identity_Heterosexual (straight)`, na.rm = TRUE),
             unsure_sexuality_pct = survey_mean(`Sexual identity_Not sure`, na.rm = TRUE),
             
             transgender_pct = survey_mean(`Transgender_Yes, I am transgender`, na.rm = TRUE),
             unsure_transgender_pct = survey_mean(`Transgender_Not sure if I am transgender`, na.rm = TRUE),
             not_transgender_pct = survey_mean(`Transgender_No`, na.rm = TRUE),
             idk_what_transgender_is_pct = survey_mean(`Transgender_DK what question is asking`, na.rm = TRUE))
dat = left_join(dat, select(yrbs, c(1, seq(2,31,2))), by = c("borough_name" = "Site code")) #join percent columns by borough, drop std error columns
dat = dat %>% mutate_at(c(1,2,3,5), as.numeric) %>% #convert numbers from character to numeric 
   dplyr::filter(!str_detect(nta_code, "99$")) #remove cemeteries
dat$borough_name = 
   str_to_title(dat$borough_name) %>% #make borough names title case
   recode("Staten_island" = "Staten Island") #remove underscore
dat = dat %>% mutate_at(c(10:15,27:41), ~ . * 100) #ensure all values are presented in the same way (proportion->percent)
```

# Export

```{r export}
uhfnames = lapply(1:32, function(x) {
   paste0(x," (", glue_collapse(
      unique(
         na.omit(dat$`UHF Neighborhood`[dat$SchoolDist==x])),
      sep=", ", last=", and "), ")")
})  #function and loop to take UHF for each school district and rename the value to include both school district and UHF neighborhoods
expdat = dat %>% 
   mutate(SchoolDist=factor(SchoolDist, 
                            levels = c(1:32), labels = c(uhfnames)))
newnames = "ZIP Code 02 Borough Code 03 ZCTA Code 04 Borough Name 05 PUMA Code 06 NTA Code 07 NTA Name 08 UHF Name 09 School District 10 White Percent 11 Black Percent 12 Hispanic Percent 13 Asian Percent 14 Bachelor's Degree or Above Percent 15 Children in Poverty Percent 16 Blood Lead Level Elevated in Children Under 6 years (Annual Average Rate per 1000 Resident Tested) 17 Asthma ED Visits in Children Age 0-4 (Annual Average Rate per 10000 Resident 0-4-year-olds) 18 Asthma ED Visits in Children Age 5-17 (Annual Average Rate per 10000 Resident 5-17-year-olds) 19 Incarceration Percent 20 High School Graduation Percent 21 Limited English Percent 22 Rent-Burdened Households Percent 23 Unemployment Percent 24 Court-Ordered Eviction (Annual Average Rate per 10000 Housing Units) 25 Number of Mental Health Facilities in ZIP Code 26 Number of Parks in ZIP Code 27 Obesity Percent 28 Overweight Percent 29 Did Not Go to School Because of Safety Concerns Percent 30 Physical Fight at School Percent 31 Bullied at School Percent 32 Physically Active One Hour Five Days a Week Percent 33 Sleeps Eight or More Hours Percent 34 Bisexual Percent 35 Gay or Lesbian Percent 36 Heterosexual Percent 37 Unsure of Sexuality Percent 38 Transgender Percent 39 Unsure if Transgender Percent 40 Not Transgender Percent 41 Doesn't Know What Transgender Means Percent" #numbered string of pretty column names
names(expdat) = unlist(str_split(gsub("\\s\\d\\d\\s", ",", newnames), ",")) #complicated code, simple purpose:
#substitute the pattern "space digit digit space" with a comma, split the string by the comma, unlist them to get separate column names in the same format as names(dat)
#this method allows for quicker and easier edits to the names of selected columns
write_xlsx(expdat, path = "C:/Users/Alex/Downloads/dashboarddata2021.xlsx") #export
```

# Data Visualization

```{r split data}
#I used this section of code for various experiments so it may look overly complicated and not particularly useful
#in the end this was just used for the built environment (parks, mh facilities) visualizations
visdat = dplyr::filter(expdat, !str_detect(`NTA Code`, "99$"))
eznames = c("zip","brcode","zcta","borname","puma","ntacode","ntaname","uhf","schdist","white","black","hisp","asian","highedu","inpov","lead","ed04","ed517","incarc","grad","eng","rent","unemp","evict","mhfac","parks","obese","ovw","unsafe","fight","bully","physact","sleep","bisex","gaylesb","straight","questioning","trans","unsuretrans","nottrans","idk")
names(visdat) = eznames #removes spaces and special characters from names and simplifies
sumfunc1 = function(x) { #combines rows by either mean or sum with x = geographic id
   summarise(x, white=mean(white,na.rm=T),black=mean(black,na.rm=T),
             hisp=mean(hisp,na.rm=T),asian=mean(asian,na.rm=T),
             highedu=mean(highedu,na.rm=T),inpov=mean(inpov,na.rm=T),
             lead=mean(lead,na.rm=T),ed04=mean(ed04,na.rm=T),
             ed517=mean(ed517,na.rm=T),incarc=mean(incarc,na.rm=T),
             grad=mean(incarc,na.rm=T),eng=mean(eng,na.rm=T),
             rent=mean(eng,na.rm=T),unemp=mean(unemp,na.rm=T),
             mhfac=sum(unique(mhfac,na.rm=T)),parks=sum(unique(parks,na.rm=T)),
             obese=mean(obese,na.rm=T),ovw=mean(ovw,na.rm=T),
             unsafe=mean(unsafe,na.rm=T),fight=mean(fight,na.rm=T),
             bully=mean(bully,na.rm=T),physact=mean(physact,na.rm=T),
             sleep=mean(sleep,na.rm=T),bisex=mean(bisex,na.rm=T),
             gaylesb=mean(gaylesb,na.rm=T),straight=mean(straight,na.rm=T),
             questioning=mean(questioning,na.rm=T),trans=mean(trans,na.rm=T),
             unsuretrans=mean(unsuretrans,na.rm=T),
             nottrans=mean(nottrans,na.rm=T),idk=mean(idk,na.rm=T))
}
sumfunc2 = function(x) { #similar to above (not sure if this second function was needed in the end)
   summarise(x, white=mean(white,na.rm=T),black=mean(black,na.rm=T),
             hisp=mean(hisp,na.rm=T),asian=mean(asian,na.rm=T),
             highedu=mean(highedu,na.rm=T),inpov=mean(inpov,na.rm=T),
             lead=mean(lead,na.rm=T),ed04=mean(ed04,na.rm=T),
             ed517=mean(ed517,na.rm=T),incarc=mean(incarc,na.rm=T),
             grad=mean(incarc,na.rm=T),eng=mean(eng,na.rm=T),
             rent=mean(eng,na.rm=T),unemp=mean(unemp,na.rm=T),
             mhfac=sum(mhfac,na.rm=T),parks=sum(parks,na.rm=T),
             obese=mean(obese,na.rm=T),ovw=mean(ovw,na.rm=T),
             unsafe=mean(unsafe,na.rm=T),fight=mean(fight,na.rm=T),
             bully=mean(bully,na.rm=T),physact=mean(physact,na.rm=T),
             sleep=mean(sleep,na.rm=T),bisex=mean(bisex,na.rm=T),
             gaylesb=mean(gaylesb,na.rm=T),straight=mean(straight,na.rm=T),
             questioning=mean(questioning,na.rm=T),trans=mean(trans,na.rm=T),
             unsuretrans=mean(unsuretrans,na.rm=T),
             nottrans=mean(nottrans,na.rm=T),idk=mean(idk,na.rm=T))
   }
zipdat = visdat[,-c(2,3,5:8)] %>% group_by(zip,schdist,borname) %>% sumfunc1 %>% #sum up zipcodes
   replace_with_na(replace = list(mhfac = NaN, parks = NaN)) #replaces NaN's with NA's
schdat = zipdat %>% group_by(schdist,borname) %>% sumfunc2 #sum up school districts
write_xlsx(schdat, path = "C:/Users/Alex/Downloads/schdat.xlsx") #export
```







